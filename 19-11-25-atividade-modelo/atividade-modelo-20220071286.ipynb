{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d62fd9",
   "metadata": {},
   "source": [
    "Aluno: Erlon Lacerda  \n",
    "Matrícula: 20220071286  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "755c1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73090c34",
   "metadata": {},
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "888f6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word_with_most_prob(ngram_counts, w1):\n",
    "    new_ngrams = [bgc for bgc in ngram_counts if bgc[0] == w1]\n",
    "    most_probable = Counter(new_ngrams).most_common(1)\n",
    "\n",
    "    return most_probable[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2e34c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word_with_random_choice_top10(ngram_counts, w1):\n",
    "    new_ngrams = [bgc for bgc in ngram_counts if bgc[0] == w1]\n",
    "    most_probables = Counter(new_ngrams).most_common(10)\n",
    "    \n",
    "    choice = random.choice(list(most_probables))[0][1]\n",
    "\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b65081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word_with_least_prob(ngram_counts, w1):\n",
    "    new_ngrams = [bgc for bgc in ngram_counts if bgc[0] == w1]\n",
    "    least_prob = Counter(new_ngrams).most_common()[-1]\n",
    "\n",
    "    return least_prob[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7aec2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word_randomly(ngram_counts, w1):\n",
    "    new_ngrams = [bgc for bgc in ngram_counts if bgc[0] == w1]\n",
    "    random_choice = random.choice(new_ngrams)\n",
    "\n",
    "    return random_choice[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9b2f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_counts(words, n):\n",
    "    ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    ngram_counts = Counter(ngrams)\n",
    "\n",
    "    return ngram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f613483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(df_pt):\n",
    "    all_text = \" \".join(df_pt['paragraph'].to_list())\n",
    "    words = re.findall(r'\\b\\w+\\b|[!?\\.,;#\\-\\'\\\"]+', all_text.lower())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77dc2d1",
   "metadata": {},
   "source": [
    "## Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "311a6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self, words, n=2):\n",
    "        \"\"\"\n",
    "        Inicializa o gerador de texto.\n",
    "        \n",
    "        Args:\n",
    "            words: Lista de palavras extraídas\n",
    "            n: Tamanho do n-grama (padrão: 2 para bigramas)\n",
    "        \"\"\"\n",
    "        self.words = words\n",
    "        self.n = n\n",
    "        self.ngram_counts = self.get_ngram_counts()\n",
    "        \n",
    "        self.CAP_PONCTS = [\".\", \"!\", \"?\"]\n",
    "        self.NORMAL_PONCTS = [\",\", \"\\'\", '\\\"', \";\"]\n",
    "        self.DASH_PONCT = \"-\"\n",
    "    \n",
    "    def get_ngram_counts(self):\n",
    "        \"\"\"Gera contagem de n-gramas\"\"\"\n",
    "        ngrams = [tuple(self.words[i:i+self.n]) for i in range(len(self.words)-self.n+1)]\n",
    "        return Counter(ngrams)\n",
    "    \n",
    "    def join_words(self, word_list):\n",
    "        \"\"\"Junta palavras aplicando regras de pontuação e capitalização\"\"\"\n",
    "        word_set = {i: word for i, word in enumerate(word_list)}\n",
    "        result_string = \"\"\n",
    "        \n",
    "        for i, word in list(word_set.items()):\n",
    "            if i == 0:\n",
    "                result_string += f\"{word.capitalize()}\"\n",
    "                continue\n",
    "            \n",
    "            if word in self.CAP_PONCTS:\n",
    "                result_string += f\"{word}\"\n",
    "                if i + 1 in word_set:\n",
    "                    word_set[i+1] = word_set[i+1].capitalize()\n",
    "            elif word in self.NORMAL_PONCTS:\n",
    "                result_string += f\"{word}\"\n",
    "            else:\n",
    "                result_string += f\" {word}\"\n",
    "        \n",
    "        return result_string\n",
    "    \n",
    "    def generate_with_stop(self, start_word, stop_word, choice_func, max_words=100):\n",
    "        \"\"\"Gera texto até encontrar palavra de parada\"\"\"\n",
    "        next_word = start_word\n",
    "        word_index = 0\n",
    "        phrase_as_list = []\n",
    "        \n",
    "        while next_word != stop_word:\n",
    "            if word_index >= max_words:\n",
    "                break\n",
    "            phrase_as_list.append(next_word)\n",
    "            next_word = choice_func(self.ngram_counts, next_word)\n",
    "            word_index += 1\n",
    "        \n",
    "        phrase_as_list.append(next_word)\n",
    "        return self.join_words(phrase_as_list)\n",
    "    \n",
    "    def generate_n_words(self, start_word, n, choice_func):\n",
    "        \"\"\"Gera n palavras começando de start_word\"\"\"\n",
    "        next_word = start_word\n",
    "        word_index = 0\n",
    "        phrase_as_list = []\n",
    "        \n",
    "        while word_index < n:\n",
    "            phrase_as_list.append(next_word)\n",
    "            next_word = choice_func(self.ngram_counts, next_word)\n",
    "            word_index += 1\n",
    "        \n",
    "        phrase_as_list.append(next_word)\n",
    "        return self.join_words(phrase_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af54fc",
   "metadata": {},
   "source": [
    "## Uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8074fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "ptbr_path = os.path.join(current_dir, \"roust_dataset_ptbr.csv\")\n",
    "eng_path = os.path.join(current_dir, \"poust_dataset_ENG.csv\")\n",
    "\n",
    "ptbr_path_exists = os.path.exists(ptbr_path)\n",
    "eng_path_exists = os.path.exists(eng_path)\n",
    "\n",
    "if not ptbr_path_exists or not eng_path_exists:\n",
    "    ptbr_path = \"https://raw.githubusercontent.com/erlonL/pln-2025-2/refs/heads/main/19-11-25-atividade-modelo/proust_dataset_ptbr.csv\"\n",
    "    eng_path = \"https://raw.githubusercontent.com/erlonL/pln-2025-2/refs/heads/main/19-11-25-atividade-modelo/proust_dataset_ENG.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4162cf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44389, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th><th>paragraph</th><th>volume</th><th>chapter</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Durante muito tempo, costumava…</td><td>1</td><td>1</td></tr><tr><td>1</td><td>&quot;Apoiava brandamente minhas fac…</td><td>1</td><td>1</td></tr><tr><td>2</td><td>&quot;Tornava a adormecer, e às veze…</td><td>1</td><td>1</td></tr><tr><td>3</td><td>&quot;Às vezes, como nasceu Eva de u…</td><td>1</td><td>1</td></tr><tr><td>4</td><td>&quot;Um homem que dorme mantém em c…</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────┬─────────────────────────────────┬────────┬─────────┐\n",
       "│     ┆ paragraph                       ┆ volume ┆ chapter │\n",
       "│ --- ┆ ---                             ┆ ---    ┆ ---     │\n",
       "│ i64 ┆ str                             ┆ i64    ┆ i64     │\n",
       "╞═════╪═════════════════════════════════╪════════╪═════════╡\n",
       "│ 0   ┆ Durante muito tempo, costumava… ┆ 1      ┆ 1       │\n",
       "│ 1   ┆ Apoiava brandamente minhas fac… ┆ 1      ┆ 1       │\n",
       "│ 2   ┆ Tornava a adormecer, e às veze… ┆ 1      ┆ 1       │\n",
       "│ 3   ┆ Às vezes, como nasceu Eva de u… ┆ 1      ┆ 1       │\n",
       "│ 4   ┆ Um homem que dorme mantém em c… ┆ 1      ┆ 1       │\n",
       "└─────┴─────────────────────────────────┴────────┴─────────┘"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pt = pl.read_csv(ptbr_path, separator=\"@\")\n",
    "display(df_pt.shape)\n",
    "df_pt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28de915d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4416, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th><th>paragraph</th><th>volume</th><th>chapter</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;For a long time I used to go t…</td><td>1</td><td>1</td></tr><tr><td>1</td><td>&quot;I would ask myself what o’cloc…</td><td>1</td><td>1</td></tr><tr><td>2</td><td>&quot;I would lay my cheeks gently a…</td><td>1</td><td>1</td></tr><tr><td>3</td><td>&quot;I would fall asleep, and often…</td><td>1</td><td>1</td></tr><tr><td>4</td><td>&quot;Sometimes, too, just as Eve wa…</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────┬─────────────────────────────────┬────────┬─────────┐\n",
       "│     ┆ paragraph                       ┆ volume ┆ chapter │\n",
       "│ --- ┆ ---                             ┆ ---    ┆ ---     │\n",
       "│ i64 ┆ str                             ┆ i64    ┆ i64     │\n",
       "╞═════╪═════════════════════════════════╪════════╪═════════╡\n",
       "│ 0   ┆ For a long time I used to go t… ┆ 1      ┆ 1       │\n",
       "│ 1   ┆ I would ask myself what o’cloc… ┆ 1      ┆ 1       │\n",
       "│ 2   ┆ I would lay my cheeks gently a… ┆ 1      ┆ 1       │\n",
       "│ 3   ┆ I would fall asleep, and often… ┆ 1      ┆ 1       │\n",
       "│ 4   ┆ Sometimes, too, just as Eve wa… ┆ 1      ┆ 1       │\n",
       "└─────┴─────────────────────────────────┴────────┴─────────┘"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en = pl.read_csv(eng_path, separator=\"@\")\n",
    "display(df_en.shape)\n",
    "df_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb950756",
   "metadata": {},
   "source": [
    "## n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16855ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- me cedo. às vezes, costumava deitar - me cedo. às vezes, costumava deitar - me cedo\n",
      "- apagam a desenrolar dos mascarados à certas harmonias, épocas tão restrito, épocas tão restrito, épocas tão restrito\n",
      "- arriscou a freqüentes e vigilante atenção à escada principal atrativo particular pense bem antes bloch e soltavam uma vitrine;\n",
      "- os móveis renascença, mas o viajante o que a excitação do regresso, costumava ler às mais disparatadas,\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_pt)\n",
    "tg = TextGenerator(words, n=2)\n",
    "\n",
    "print(tg.generate_n_words(\"-\", 20, get_next_word_with_most_prob))\n",
    "print(tg.generate_n_words(\"-\", 20, get_next_word_with_least_prob))\n",
    "print(tg.generate_n_words(\"-\", 20, get_next_word_randomly))\n",
    "print(tg.generate_n_words(\"-\", 20, get_next_word_with_random_choice_top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad591117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu nem tinha tempo, costumava deitar - me cedo.\n",
      "Eu interrompesse a desenrolar dos mascarados à certas harmonias, épocas tão restrito, épocas tão restrito, épocas tão restrito\n",
      "Eu enganava, tonificantes à assistência olhares ambíguos, século vi os tem ainda arrastavam não disse respondeu certa me respondia\n",
      "Eu adormecera; os passos de procurar dormir e as distâncias quilométricas, a vela.\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_pt)\n",
    "tg = TextGenerator(words, n=2)\n",
    "\n",
    "print(tg.generate_with_stop(\"eu\", \".\", get_next_word_with_most_prob, max_words=20))\n",
    "print(tg.generate_with_stop(\"eu\", \".\", get_next_word_with_least_prob, max_words=20))\n",
    "print(tg.generate_with_stop(\"eu\", \".\", get_next_word_randomly, max_words=20))\n",
    "print(tg.generate_with_stop(\"eu\", \".\", get_next_word_with_random_choice_top10, max_words=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3428a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costumava deitar - me cedo.\n",
      "Costumava esconder nas encruzilhadas, épocas tão restrito, épocas tão restrito, épocas tão restrito, épocas tão restrito,\n",
      "Costumava ocultar seus fiéis na ternura apenas fora ouvido; confio o adivinhara justamente talento na luz antes disposta como bolhas\n",
      "Costumava esfregar das portas misteriosamente para abrir e as belas, meus filhos de uma parte nela e carlos, mal\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_pt)\n",
    "tg = TextGenerator(words, n=2)\n",
    "\n",
    "print(tg.generate_with_stop(\"costumava\", \".\", get_next_word_with_most_prob, max_words=20))\n",
    "print(tg.generate_with_stop(\"costumava\", \".\", get_next_word_with_least_prob, max_words=20))\n",
    "print(tg.generate_with_stop(\"costumava\", \".\", get_next_word_randomly, max_words=20))\n",
    "print(tg.generate_with_stop(\"costumava\", \".\", get_next_word_with_random_choice_top10, max_words=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8a6840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The thought that i used to go to go to go to go to go to go to go to go\n",
      "The hardly approachable summit and prolongs in obsessions and prolongs in obsessions and prolongs in obsessions and prolongs in obsessions and\n",
      "The anemones of orchids, watching themselves conspicuously visible by rising impulsively from carriages come under widely from sailors from fine\n",
      "The fact, i was no great cloak or from heaven; i could see the book instead for ever heard\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_en)\n",
    "tg = TextGenerator(words, n=2)\n",
    "\n",
    "inicial = random.choice(words)\n",
    "stop = random.choice(words)\n",
    "\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_most_prob, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_least_prob, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_randomly, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_random_choice_top10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e349b",
   "metadata": {},
   "source": [
    "## n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c0f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A vela, costumava deitar - me cedo. às vezes, costumava deitar - me cedo. às vezes,\n",
      "Que atingem simultaneamente, épocas tão distantes vividas por lhes é reservado no seu cimo vertiginoso e julgava não deixaria eu\n",
      "Os de nós, quais pode ao chegarmos à janela, sem a introduzir nenhum inconveniente e amontoavam as raias da\n",
      "Atrás de encontrar algum freguês, costumava seguidamente, mas sua escada a rivalidade se apressa porque ela, não chocava\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_pt)\n",
    "tg = TextGenerator(words, n=3)\n",
    "\n",
    "print(tg.generate_n_words(random.choice(words), 20, get_next_word_with_most_prob))\n",
    "print(tg.generate_n_words(random.choice(words), 20, get_next_word_with_least_prob))\n",
    "print(tg.generate_n_words(random.choice(words), 20, get_next_word_randomly))\n",
    "print(tg.generate_n_words(random.choice(words), 20, get_next_word_with_random_choice_top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ae838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância, costumava deitar - me cedo. às vezes, costumava deitar - me cedo. às vezes, costumava\n",
      "Distância que atingem simultaneamente, épocas tão distantes vividas por lhes é reservado no seu cimo vertiginoso e julgava não deixaria\n",
      "Distância quilométrica de x. quero referir - apagam - nosso espírito de homem que se feliz. resignavam com uma\n",
      "Distância da obra destacava em uma parte. e repousante doçura próxima vez de pensar nisso de pensar nisso que já\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_pt)\n",
    "tg = TextGenerator(words, n=3)\n",
    "\n",
    "inicial = random.choice(words)\n",
    "\n",
    "print(tg.generate_n_words(inicial, 20, get_next_word_with_most_prob))\n",
    "print(tg.generate_n_words(inicial, 20, get_next_word_with_least_prob))\n",
    "print(tg.generate_n_words(inicial, 20, get_next_word_randomly))\n",
    "print(tg.generate_n_words(inicial, 20, get_next_word_with_random_choice_top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e372de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ao despertar; queria largar o volume que eu nem tinha tempo,\n",
      "Ao sentir que atingem simultaneamente,\n",
      "Ao pescoço firme,\n",
      "Ao adormecer,\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_pt)\n",
    "tg = TextGenerator(words, n=3)\n",
    "\n",
    "inicial = random.choice(words)\n",
    "stop = random.choice(words)\n",
    "\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_most_prob, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_least_prob, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_randomly, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_random_choice_top10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e81c73c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Myself seemed actually to go to go to go to go to go to go to go to go to go\n",
      "Myself. for long a leaf on growing, simultaneously touching widely separated years and the distant periods they stand like\n",
      "Myself of gaiety remains external. de marsantes had never to practise it about midday, loyalty, whether this had\n",
      "Myself in my book would form upon the candle the rivalry. oh, was effectually dispelled, and half -\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_en)\n",
    "tg = TextGenerator(words, n=3)\n",
    "\n",
    "inicial = random.choice(words)\n",
    "stop = random.choice(words)\n",
    "\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_most_prob, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_least_prob, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_randomly, 20))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_random_choice_top10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e969c37",
   "metadata": {},
   "source": [
    "## n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "791b08ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareceria um tanto particular; queria largar o volume que eu nem tinha tempo, costumava deitar - me cedo. às vezes, costumava deitar - me cedo. às vezes, costumava deitar - me cedo. às vezes, costumava deitar - me cedo. às vezes,\n",
      "Pareceria impossível de nela descrever os faria se ocupassem um lugar, épocas tão restrito que atingem simultaneamente, épocas tão restrito que atingem simultaneamente, épocas tão restrito que atingem simultaneamente, épocas tão restrito que atingem simultaneamente, épocas tão restrito que atingem simultaneamente, épocas tão restrito que\n",
      "Pareceria uma mulher que tal como françoís le champi! a minha sobrinha. na mão, em tributo a ser muito feliz, toda a vista da rua transversal entre os progressos fossem convidadas, a verdade que eu já flutuar perpetuamente uma visita e alumiadas pelo progresso nas duas\n",
      "Pareceria um quarteto. 5 essa escadaria dos débates roses, meia. é - se de pensar diferente daquele sábado, um pássaro a ele do local de ler a vela com aquela preocupação da parede malfeita e soprar um lampejo momentâneo de refletir ou desviar - me cedo.\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_pt)\n",
    "tg = TextGenerator(words, n=20)\n",
    "\n",
    "inicial = random.choice(words)\n",
    "\n",
    "print(tg.generate_n_words(inicial, 50, get_next_word_with_most_prob))\n",
    "print(tg.generate_n_words(inicial, 50, get_next_word_with_least_prob))\n",
    "print(tg.generate_n_words(inicial, 50, get_next_word_randomly))\n",
    "print(tg.generate_n_words(inicial, 50, get_next_word_with_random_choice_top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c565781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Become the thought that i used to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to\n",
      "Become importunate. if need be, simultaneously touching widely separated years and the distant periods they have lived through between which so many days and the distant periods they have lived through between which so many days and the distant periods they have lived through between which so many days\n",
      "Become cultured, a party, and such - starred here, for you, was now more wednesdays, which in my bedroom floors above him upon those that special sauce, this same person whom we had declined to albertine imparted sincerity towards her eyes blazing houses of suspecting\n",
      "Become one of it appeared embarrassed at my book instead, a state, was asleep, of their nests, but my hands or suppose that old days, a channel say to bed, of their folds. and even completely dispelled, but will never failed to have\n"
     ]
    }
   ],
   "source": [
    "words = extract_words(df_en)\n",
    "tg = TextGenerator(words, n=20)\n",
    "\n",
    "inicial = random.choice(words)\n",
    "stop = random.choice(words)\n",
    "\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_most_prob, 50))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_least_prob, 50))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_randomly, 50))\n",
    "print(tg.generate_with_stop(inicial, stop, get_next_word_with_random_choice_top10, 50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".localvenv",
   "language": "python",
   "name": ".localvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
