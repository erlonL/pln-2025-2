{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeebd865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets --quiet\n",
    "%pip install nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "385a026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b2dec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('tweets_hate_speech_detection', cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c7b91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'tweet'],\n",
       "        num_rows: 31962\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'tweet'],\n",
       "        num_rows: 17197\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "549c5f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['tweet'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6581afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/erlon-\n",
      "[nltk_data]     lacerda/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "643a6bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'user',\n",
       " '@',\n",
       " 'user',\n",
       " 'thanks',\n",
       " 'for',\n",
       " '#',\n",
       " 'lyft',\n",
       " 'credit',\n",
       " 'i',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'use',\n",
       " 'cause',\n",
       " 'they',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'offer',\n",
       " 'wheelchair',\n",
       " 'vans',\n",
       " 'in',\n",
       " 'pdx',\n",
       " '.',\n",
       " '#',\n",
       " 'disapointed',\n",
       " '#',\n",
       " 'getthanked']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(dataset['train']['tweet'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f51748b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'tweet'],\n",
       "    num_rows: 31962\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29edd5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens(row):\n",
    "    text = row['tweet']\n",
    "\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    row['tokens'] = tokens\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f28675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 31962/31962 [00:06<00:00, 5267.62 examples/s]\n",
      "Map: 100%|██████████| 17197/17197 [00:03<00:00, 5362.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'tweet', 'tokens'],\n",
       "        num_rows: 31962\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'tweet', 'tokens'],\n",
       "        num_rows: 17197\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(split_tokens)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d2e027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8f5c25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'user',\n",
       " 'when',\n",
       " 'a',\n",
       " 'father',\n",
       " 'is',\n",
       " 'dysfunctional',\n",
       " 'and',\n",
       " 'is',\n",
       " 'so',\n",
       " 'selfish',\n",
       " 'he',\n",
       " 'drags',\n",
       " 'his',\n",
       " 'kids',\n",
       " 'into',\n",
       " 'his',\n",
       " 'dysfunction',\n",
       " '.',\n",
       " '#',\n",
       " 'run']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd1f6947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575990"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = []\n",
    "\n",
    "for tokens in dataset['train']['tokens']:\n",
    "  all_tokens.extend(tokens)\n",
    "\n",
    "len(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "727a2607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', 76675),\n",
       " ('@', 18212),\n",
       " ('user', 17577),\n",
       " ('!', 14650),\n",
       " ('.', 12133),\n",
       " ('the', 10147),\n",
       " ('to', 9833),\n",
       " ('i', 7161),\n",
       " ('a', 6449),\n",
       " (',', 6305),\n",
       " ('you', 5867),\n",
       " ('and', 4903),\n",
       " ('in', 4644),\n",
       " ('for', 4492),\n",
       " ('is', 4292),\n",
       " ('of', 4168),\n",
       " ('my', 3689),\n",
       " ('it', 3570),\n",
       " (\"'s\", 3219),\n",
       " (':', 3092),\n",
       " ('love', 2739),\n",
       " ('this', 2665),\n",
       " ('on', 2634),\n",
       " ('?', 2600),\n",
       " ('with', 2520),\n",
       " ('be', 2459),\n",
       " (';', 2451),\n",
       " ('...', 2314),\n",
       " ('day', 2258),\n",
       " ('&', 2256),\n",
       " (\"n't\", 2228),\n",
       " ('that', 2050),\n",
       " ('so', 1986),\n",
       " ('all', 1943),\n",
       " ('are', 1932),\n",
       " ('do', 1844),\n",
       " ('me', 1832),\n",
       " ('amp', 1776),\n",
       " ('your', 1697),\n",
       " ('have', 1684),\n",
       " ('happy', 1653),\n",
       " ('at', 1645),\n",
       " ('we', 1549),\n",
       " ('-', 1370),\n",
       " ('just', 1359),\n",
       " ('not', 1282),\n",
       " ('will', 1271),\n",
       " ('when', 1267),\n",
       " ('am', 1176),\n",
       " ('what', 1163)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(all_tokens)\n",
    "counts.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aac381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poshpretzels',\n",
       " 'foodie',\n",
       " 'cosplay',\n",
       " 'illwait',\n",
       " 'â£77',\n",
       " 'dram',\n",
       " 'protectlove',\n",
       " 'scamming',\n",
       " 'riding',\n",
       " 'creeper',\n",
       " 'farahdhukai',\n",
       " 'sho',\n",
       " 'whispering',\n",
       " 'neverdelta',\n",
       " 'occasional',\n",
       " 'ushered',\n",
       " 'justsayingâ\\x80¦',\n",
       " 'reich',\n",
       " 'prayerworks',\n",
       " 'industrial']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(all_tokens))\n",
    "vocab[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed69b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47109"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c449ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'anmol_yadien'),\n",
       " (1, 'pepsicenterwtc'),\n",
       " (2, 'whatwomenwant'),\n",
       " (3, '2017.'),\n",
       " (4, 'disgusts'),\n",
       " (5, 'marioaavia'),\n",
       " (6, 'neverforogotten'),\n",
       " (7, 'webcam'),\n",
       " (8, 'mounting'),\n",
       " (9, '1.2900'),\n",
       " (10, 'schools'),\n",
       " (11, 'numbersdontlie'),\n",
       " (12, 'conve'),\n",
       " (13, 'breitba'),\n",
       " (14, 'geeks'),\n",
       " (15, 'allgrownup'),\n",
       " (16, 'capitolhillgraffix'),\n",
       " (17, 'cool'),\n",
       " (18, 'allys'),\n",
       " (19, 'poundsign'),\n",
       " (20, 'eeekk'),\n",
       " (21, 'goto'),\n",
       " (22, 'tossed'),\n",
       " (23, 'yogaretreat'),\n",
       " (24, 'ironies'),\n",
       " (25, 'nannycramps'),\n",
       " (26, 'embroidery'),\n",
       " (27, 'childrenâ\\x9d£our'),\n",
       " (28, 'hastieweekend'),\n",
       " (29, 'mobileapps'),\n",
       " (30, 'respectful'),\n",
       " (31, 'caused'),\n",
       " (32, 'fuâ\\x80¦'),\n",
       " (33, 'rem'),\n",
       " (34, 'grinding'),\n",
       " (35, 'youtu'),\n",
       " (36, 'stmoritz'),\n",
       " (37, 'daventry'),\n",
       " (38, 'straighten'),\n",
       " (39, 'wots'),\n",
       " (40, 'faim'),\n",
       " (41, 'chototel'),\n",
       " (42, 'initiative'),\n",
       " (43, 'weeklongcelebration'),\n",
       " (44, 'aj'),\n",
       " (45, 'happyholidayð\\x9f\\x8c´ð\\x9f\\x92\\x96ð\\x9f\\x92\\x96'),\n",
       " (46, 'dealers'),\n",
       " (47, 'donthecon'),\n",
       " (48, 'rings'),\n",
       " (49, 'cravenhouse'),\n",
       " (50, 'roger'),\n",
       " (51, 'niki'),\n",
       " (52, 'mandalað\\x9f\\x8e¨â\\x9c¨ð\\x9f\\x8c\\x9e'),\n",
       " (53,\n",
       "  '.ð\\x9f\\x98\\x9að\\x9f\\x98\\x9að\\x9f\\x98\\x8eð\\x9f\\x98\\x8eð\\x9f\\x98\\x8eð\\x9f\\x98\\x8e'),\n",
       " (54, 'ð\\x9f\\x92\\x87ð\\x9f\\x8f'),\n",
       " (55, 'lifetips'),\n",
       " (56, 'challah'),\n",
       " (57, 'ra'),\n",
       " (58, 'inspire'),\n",
       " (59, 'phopo'),\n",
       " (60, 'fuccckkkk'),\n",
       " (61, 'flick'),\n",
       " (62, 'nyklippt'),\n",
       " (63, 'finding'),\n",
       " (64, 'zaatar'),\n",
       " (65, 'asap'),\n",
       " (66, 'cooked'),\n",
       " (67, 'clients'),\n",
       " (68, 'allð\\x9f\\x92§'),\n",
       " (69, 'wisdom2016'),\n",
       " (70, 'magicrealism'),\n",
       " (71, 'nakuru'),\n",
       " (72, 'bttf'),\n",
       " (73, 'officiating'),\n",
       " (74, 'gencyber'),\n",
       " (75, 'ã\\x82\\x84ã\\x81\\x91ã\\x81\\x9f'),\n",
       " (76, 'gloria'),\n",
       " (77, 'suffrage'),\n",
       " (78, 'bangsean'),\n",
       " (79, 'illustrations'),\n",
       " (80, 'staffie'),\n",
       " (81, 'prayforoakland'),\n",
       " (82, '18'),\n",
       " (83, 'speculative'),\n",
       " (84, 'legallyblonde'),\n",
       " (85, 'â\\x80¢â\\x80¢â\\x80¢'),\n",
       " (86, 'ð\\x9f\\x98\\x83ð\\x9f\\x98\\x83ð\\x9f\\x98\\x83'),\n",
       " (87, 'myselfie'),\n",
       " (88, 'superspoilt'),\n",
       " (89, 'babbar'),\n",
       " (90, 'ó¾\\x8c¬ó¾\\xad©'),\n",
       " (91, 'pridela'),\n",
       " (92, 'balconyview'),\n",
       " (93, 'ditching'),\n",
       " (94, 'tryouts'),\n",
       " (95, 'seasideâ\\x80¦'),\n",
       " (96, 'roydsllp'),\n",
       " (97, 'pin'),\n",
       " (98, 'anti-'),\n",
       " (99, 'smirk')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(vocab))[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc8b24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id = {token: idx for idx, token in enumerate(vocab)}\n",
    "id2token = {idx: token for idx, token in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84353e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34423"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2id['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f028c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(row):\n",
    "  window_size = 2\n",
    "\n",
    "  doc = row['tokens']\n",
    "  out = []\n",
    "\n",
    "  for i, token in enumerate(doc):\n",
    "    target = token2id[token]\n",
    "\n",
    "    aux = []\n",
    "\n",
    "    for j in range(-window_size, window_size+1): # -2, -1, 0, 1, 2\n",
    "      index = i + j\n",
    "\n",
    "      if index < 0 or index >= len(doc) or j == 0:\n",
    "        continue\n",
    "\n",
    "      aux.append((target, token2id[doc[index]]))\n",
    "\n",
    "    out.extend(aux)\n",
    "\n",
    "  row['window'] = out\n",
    "\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e01079c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 31962/31962 [00:04<00:00, 6450.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset['train'].map(sliding_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f16f64",
   "metadata": {},
   "source": [
    "## Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "174b68ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/erlon-lacerda/.localvenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8889eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a0468a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init len e getitem são metodos especiais e sempre precisam existir\n",
    "\n",
    "class Word2VecDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = []\n",
    "\n",
    "        for row in dataset:\n",
    "            self.data.extend(row['window'])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f2a800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = Word2VecDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79d4400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2112188"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a67481fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(my_dataset, batch_size=1024, shuffle=True) \n",
    "# shuffle: ordem pode enviesar o treinamento\n",
    "# batch_size: quanto mais exemplos passamos garante com que o treino seja menos caótico,\n",
    "#  porque o erro vai ficar mais \"smooth\"\n",
    "#  ao invés de atualizar a cada exemplo, atualizamos por lote\n",
    "#  batch muito grande pode fazer estourar a memória da gpu (com datasets grandes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eadfb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b4235fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # camadas da nn\n",
    "        #   camada de embedding\n",
    "        #   vocab: tamanho da entrada, mapea cada token único\n",
    "        #   embedding: tamanho de saída\n",
    "        #   tensor: array multidimensional necessário do pytorch. pra cada índice que eu tenho,\n",
    "        #           retorna um vetor de tamanho = embedding_dim\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        #   fully connected\n",
    "        #   entrada: tamanho do embedding\n",
    "        #   saída: tamanho do vocabulário ([0.007, 0.003, 0.96, ..., 0.001, 0.0001, 0.001]),\n",
    "        #        pegamos qual a palavra por ID / posição\n",
    "        #        sempre normalizamos pra soma do vetor dar 1\n",
    "        self.expand = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # só precisamos fazer o forward, o backpropagation é gerenciado pela biblioteca\n",
    "        embed_vector = self.embed(x)\n",
    "        output = self.expand(embed_vector)\n",
    "\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3001652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3813,  0.8177, -0.4879, -0.1398, -0.1687, -0.8883,  0.5411, -0.1329,\n",
       "        -0.8042, -0.1588,  0.4469, -0.7666,  0.0092, -1.5939,  0.6247, -0.5412,\n",
       "         0.5138, -0.6411, -1.3114, -1.4391,  1.3103, -0.3527, -0.0523, -0.2927,\n",
       "         0.1437, -0.5714, -0.7079,  0.1213,  1.3280, -0.2288, -0.0366,  1.0107,\n",
       "         1.2149,  0.7570, -1.0796, -1.5025,  2.4938, -0.5190,  0.1829,  1.5362,\n",
       "         0.6297, -1.5364, -0.0296,  0.9828,  0.5139, -0.1535, -0.0271,  0.1504,\n",
       "        -0.3378,  0.3695], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_test = nn.Embedding(len(vocab), 50)\n",
    "\n",
    "display(embedding_test(torch.tensor(10))) # retorna um vetor de tamanho 50 inicializado de forma aleatória\n",
    "\n",
    "display(embedding_test(torch.tensor(10)).shape) # 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1ef3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Word2Vec(len(vocab), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "041843a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47109])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network(torch.tensor(10)) # chama o forward\n",
    "\n",
    "display(network(torch.tensor(10)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bd0d95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18456)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.4612, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = network(torch.tensor(10))\n",
    "\n",
    "display(result.argmax())\n",
    "\n",
    "result[30983]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "236be4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('schools', 'eldest')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2token[10], id2token[30983]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38336f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ultimo passo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34d4bfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (embed): Embedding(47109, 50)\n",
       "  (expand): Linear(in_features=50, out_features=47109, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 5\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# se eu tenho valores que são iguais vai tender a 0. Quanto mais dif tende a infinito\n",
    "optimizer = torch.optim.AdamW(network.parameters(), lr=LR)\n",
    "# otimizador: baseados no gradiente descendente, mas tem alguns ajustes de LR de forma dinâmica\n",
    "#   pra garantir aprendizado\n",
    "#   no começo ajustamos bastante, talvez no final precisemos ajustar bem pouco\n",
    "#   outro uso: você usou um tamanho de passo, se for bom aumenta, se começar a piorar diminui\n",
    "\n",
    "# o dado e a rede precisa estar no mesmo device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "network.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for input, context in dataloader:\n",
    "        input = input.to(device)\n",
    "        print('input: ', input)\n",
    "        print('input shape: ', input.shape)\n",
    "        context = context.to(device)\n",
    "        print('context: ', context)\n",
    "        print('context shape: ', context.shape)\n",
    "\n",
    "        # input: primeiro elemento da tupla\n",
    "        # context: segundo elemento da tupla\n",
    "        # ('house', 'dog')\n",
    "\n",
    "\n",
    "        output = network(input)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # fazemos pra fazer uma nova atualização de peso\n",
    "\n",
    "        loss = loss_fn(output, context) # saber quanto erramoszes\n",
    "        # debug\n",
    "        break\n",
    "\n",
    "        epoch_loss += loss.item() # monitorar as losszes\n",
    "\n",
    "        loss.backward() # calcula os gradientes\n",
    "        optimizer.step() # atualiza os pesos\n",
    "\n",
    "    # torch.save(model.state_dict(), f'word2vec-{i}.pt')\n",
    "    all_losses.append(epoch_loss)\n",
    "    print(f\"Epoch {i} loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b06e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1050/2063 [06:00<05:47,  2.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     loss = loss_fn(output, context) \u001b[38;5;66;03m# saber quanto erramoszes\u001b[39;00m\n\u001b[32m     18\u001b[39m     epoch_loss += loss.item() \u001b[38;5;66;03m# monitorar as losszes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# calcula os gradientes\u001b[39;00m\n\u001b[32m     21\u001b[39m     optimizer.step() \u001b[38;5;66;03m# atualiza os pesos\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# torch.save(model.state_dict(), f'word2vec-{i}.pt')\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.localvenv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.localvenv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.localvenv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for input, context in tqdm(dataloader):\n",
    "        input = input.to(device)\n",
    "        context = context.to(device)\n",
    "\n",
    "        output = network(input)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # fazemos pra fazer uma nova atualização de peso\n",
    "\n",
    "        loss = loss_fn(output, context) # saber quanto erramoszes\n",
    "        epoch_loss += loss.item() # monitorar as losszes\n",
    "\n",
    "        loss.backward() # calcula os gradientes\n",
    "        optimizer.step() # atualiza os pesos\n",
    "\n",
    "    # torch.save(model.state_dict(), f'word2vec-{i}.pt')\n",
    "    all_losses.append(epoch_loss)\n",
    "    print(f\"Epoch {i} loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c60c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'word2vec.pt')\n",
    "torch.load('word2vec.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como acessar os embeddings?\n",
    "\n",
    "word2vecs = network.expand.weight.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c33397",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vecs[token2id['here']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distancia das palavras\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8144e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = word2vecs[token2id['father']]\n",
    "w2 = word2vecs[token2id['mother']]\n",
    "\n",
    "distance.pdist([w1, w2], 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = word2vecs[token2id['mother']]\n",
    "w2 = word2vecs[token2id['hate']]\n",
    "\n",
    "distance.pdist([w1, w2], 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413be520",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = word2vecs[token2id['hate']]\n",
    "w2 = word2vecs[token2id['speech']]\n",
    "\n",
    "distance.pdist([w1, w2], 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c40d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = word2vecs[token2id['mars']]\n",
    "w2 = word2vecs[token2id['milk']]\n",
    "\n",
    "distance.pdist([w1, w2], 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular rankeamento de palavras mais similares\n",
    "# pode ser feito com sklearn cosine similarity\n",
    "\n",
    "word_embedding = word2vecs[token2id['hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualização dos embeddings, transformando os vetores em 2 dimensões    \n",
    "# TAREFINHA DE CASAAAAAAAAAAAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".localvenv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
